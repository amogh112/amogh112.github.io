<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Amogh Gupta</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:70%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Amogh Gupta
                </p>
                <p>
                  I am an Applied Scientist at Amazon. 
                  My interests include representation learning, 3D computer vision (human body reconstruction, neural rendering, pose estimation), generative modeling, on-device machine learning and AR, human centered design and human computer interaction among others. 
                  <br>
                  <br>
                  Previously, I did my MS in Computer Science at Columbia University where I was fortunate to be advised by Professor Carl Vondrick. Even before, I completed my undergraduate studies at Indian Institute of Technology, Delhi where I worked on autonomous robotics with Professor Sunil Jha.

                </p>
                <p style="text-align:center">
                  <a href="mailto:amogh112@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Amogh_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=GckWe2cAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/amogh112/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/amogh_image.png"><img style="width:100%;max-width:200px;object-fit: cover; border-radius: 10px;" alt="profile photo" src="images/amogh_image.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <!-- <p>
                  I'm interested in computer vision, deep learning, adversarial robustness, and multi-task learning. My research focuses on making deep learning models more robust and reliable, particularly through multi-task learning approaches and generative modeling techniques. Some papers are <span class="highlight">highlighted</span>.
                </p> -->
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src='images/genit.png' width=100% style="border-radius: 10px;">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Mao_Generative_Interventions_for_Causal_Learning_CVPR_2021_paper.html">
          <span class="papertitle">Generative Interventions for Causal Learning</span>
        </a>
        <br>
        Chengzhi Mao, Augustine Cha*, <strong>Amogh Gupta*</strong>, Hao Wang, Junfeng Yang, Carl Vondrick
        <br>
        <em>CVPR</em>, 2021
        <br>
        <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mao_Generative_Interventions_for_Causal_Learning_CVPR_2021_paper.pdf">paper</a>
        /
        <a href="https://github.com/cvlab-columbia/GenInt">code</a>
        <p></p>
        <p>
        Proposed framework by steering in latent space of GANs to mitigate spurious correlations in image classification.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src='images/multitask.png' width=100% style="border-radius: 10px;">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470154.pdf">
          <span class="papertitle">Multi-Task Learning Strengthens Adversarial Robustness</span>
        </a>
        <br>
        Chengzhi Mao, <strong>Amogh Gupta*</strong>, Vikram Nitin*, Baishakhi Ray, Shuran Song, Junfeng Yang, Carl Vondrick
        <br>
        <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470154.pdf">paper</a>
        /
        <a href="https://github.com/columbia/MTRobust">code</a>
        <p></p>
        <p>
        Showed that multi-task learning can make deep learning models robust in 11 computer vision tasks such as semantic segmentation, depth estimation etc.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src='images/robotutor.png' width=100% style="border-radius: 10px;">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://www.cmu.edu/scs/robotutor/">
          <span class="papertitle">RoboTutor</span>
        </a>
        <br>
        <a href="https://www.cmu.edu/scs/robotutor/">website</a>
        /
        <a href="https://www.youtube.com/watch?v=NFFC3nOLSQ0">video</a>
        /
        <a href="https://github.com/XPRIZE/GLEXP-Team-RoboTutor-RoboTutor">code</a>
        
        <p></p>
        <p>
        RoboTutor is an open-source Android tablet app that enables children ages 7-10 with little or no access to schools to learn basic reading, writing, and arithmetic without adult assistance. It was one of five finalists in XPrize Global Learning Challenge.
        </p>
      </td>
    </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Industry</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src='images/vto_shoes.png' width=100% style="border-radius: 10px;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <strong>AR - Virtual Shoe Try-On</strong>
                <br>
                <a href="https://www.amazon.com/b?node=23595320011&amp;pd_rd_w=cd330&amp;content-id=amzn1.sym.75e526c4-217e-464f-9652-d29a30f7024c:amzn1.sym.75e526c4-217e-464f-9652-d29a30f7024c&amp;pf_rd_p=75e526c4-217e-464f-9652-d29a30f7024c&amp;pf_rd_r=J5FR0WBQSRDRB851BM8H&amp;pd_rd_wg=I6Jou&amp;pd_rd_r=e00cc793-7c2d-479b-8e78-2cdf88f71d9c&amp;qid=1764710973&amp;ref_=sxts_snpl_1_0_75e526c4-217e-464f-9652-d29a30f7024c">website</a>
                /
                <a href="https://www.youtube.com/watch?v=ZjroiqNf2VM">video</a>
                <br>
                Press: 
                <a href="https://techcrunch.com/2022/06/09/amazon-gets-into-ar-shopping-with-launch-of-virtual-try-on-for-shoes/">TechCrunch</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Patents</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <strong>Virtual Shoe Try-On</strong> - U.S. Patent No. 11,978,174
                <a href="https://pubchem.ncbi.nlm.nih.gov/patent/US-11978174-B1">[Link]</a>
                <br>
                Yuelong Li, Gitika Karumuri, Miriam Bellver, Sunil Hadap, Ashwin Swaminathan, <strong>Amogh Gupta</strong>, Xin Shen
                <br><br>
                <strong>Reducing False Positives Based on Classification and Segmentation Cues</strong> - U.S. Patent No. 12,211,090
                <a href="https://pubchem.ncbi.nlm.nih.gov/patent/US-12211090-B1">[Link]</a>
                <br>
                Gitika Karumuri, Miriam Bellver, <strong>Amogh Gupta</strong>, Ashwin Swaminathan, Sunil Hadap, Yuelong Li, Xin Shen
              </td>
            </tr>
          </tbody></table>

          
					<!-- <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             -->
           
            <!-- <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr> -->
<!-- 
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Reviewer, ICLR 2024</a>
                <br>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Teaching Assistant, Advanced Software Engineering</a>
                <br>
                
              </td>
            </tr> -->
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Website template borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
